{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea53f5ec-af17-4e69-b5e2-7fd36ff51be5",
   "metadata": {},
   "source": [
    "**LinkedIn Profile:** [Matencio Montana](https://www.linkedin.com/in/montana-matencio-b01111376)  \n",
    "**Contact:** [montana.matencio@gmail.com](mailto:montana.matencio@gmail.com)\n",
    "\n",
    "\n",
    "**Rock Paper Scissors Classification: A Deep Learning Approach**\n",
    "\n",
    "\n",
    "**Project Overview**\n",
    "This project explores the exciting use of deep learning in computer vision. It involves building and testing models that can classify hand gestures for the game of Rock, Paper, and Scissors. By training on a special dataset of hand images, the goal is to create smart systems that accurately recognize these gestures.\n",
    "\n",
    "**Technologies & Methodologies**\n",
    "This project leverages a comprehensive suite of Python libraries and deep learning methodologies:\n",
    "\n",
    "- Python: The core programming language underpinning the entire project.\n",
    "\n",
    "- Pandas & NumPy: Utilized for efficient data loading, manipulation, and numerical operations, particularly in handling the dataset's metadata (CSV files).\n",
    "\n",
    "- PyTorch: The chosen deep learning framework, providing the flexibility and power to define, train, and evaluate neural network architectures.\n",
    "\n",
    "- CNN (Convolutional Neural Network): The fundamental deep learning architecture implemented (RockPaperScissorsCNN), specifically designed for its superior performance in image recognition and classification tasks.\n",
    "\n",
    "- Residual Networks (ResNet): A key architectural enhancement, implemented through ResBlock components and integrated into RockPaperScissorsResNetwork, allowing for the training of deeper networks by mitigating the vanishing gradient problem and improving learning efficiency.\n",
    "\n",
    "- torchvision.transforms: Used for crucial image preprocessing steps, including resizing images to a uniform IMAGE_SIZE (set to 16x16 pixels), and applying data augmentation techniques like RandomHorizontalFlip, RandomRotation(10), and ColorJitter to enhance model generalization and robustness.\n",
    "\n",
    "- Batch Normalization & Dropout: Integrated within both CNN and ResNet architectures (nn.BatchNorm2d, nn.Dropout) to improve training stability, accelerate convergence, and serve as effective regularization techniques to prevent overfitting.\n",
    "\n",
    "- DataLoader and Dataset: Custom RockPaperScissorsDataset and DataLoader classes are implemented for efficient batching and loading of image data during training and evaluation.\n",
    "\n",
    "- Loss Function & Optimizer: nn.CrossEntropyLoss is used as the loss function for multi-class classification, and torch.optim.AdamW is employed as the optimizer for model training.\n",
    "\n",
    "- Learning Rate Scheduler: lr_scheduler.CosineAnnealingLR is used to dynamically adjust the learning rate during training, further optimizing model convergence.\n",
    "\n",
    "**Data Source**\n",
    "The models are trained and evaluated on a specialized, Open Source dataset containing images of hands forming Rock, Paper, and Scissors gestures. This dataset is organized with separate training and test directories (rock-paper-scissors/train/train/, rock-paper-scissors/test/test/), accompanied by annotation CSV files (_annotations.csv), which facilitate structured data loading and labeling. The images in this dataset were collected from various sources and augmented to create a diverse dataset. The dataset used is \"Rock-Paper-Scissors\" by Adil Shamim, available on Kaggle: https://www.kaggle.com/datasets/adilshamim8/rock-paper-scissors.\n",
    "\n",
    "**Notebook/Project Structure**\n",
    "\n",
    "- Data Loading & Preprocessing: This initial phase involves reading annotation CSV files using Pandas, inspecting data distribution, and defining torchvision.transforms for image resizing, normalization, and data augmentation. A custom RockPaperScissorsDataset class handles image loading and label mapping.\n",
    "\n",
    "- Dataset & DataLoader Creation: PyTorch DataLoader objects are created for both training and evaluation sets, enabling efficient batch processing of image data.\n",
    "\n",
    "- Model Definition: Two distinct Convolutional Neural Network architectures are defined and explored:\n",
    "\n",
    "    - RockPaperScissorsCNN: A simpler, sequential CNN model.\n",
    "\n",
    "    - RockPaperScissorsResNetwork: A more advanced network incorporating ResBlock for residual connections, enabling deeper and more powerful feature extraction.\n",
    "\n",
    "- Training & Evaluation Loops: Dedicated training_loop and evaluate_loop functions manage the training iterations, forward passes, backpropagation, optimizer steps, and performance monitoring (loss and accuracy).\n",
    "\n",
    "- Model Training & Hyperparameters: Both models are trained for 50 epochs using CrossEntropyLoss and AdamW optimizer, with learning rate scheduling.\n",
    "\n",
    "**Key Findings & Model Performance**\n",
    "After 50 epochs of training, significant differences in performance were observed between the two architectures, demonstrating that both models are effectively learning to classify hand gestures, performing significantly better than random chance (which would yield approximately 33.3% accuracy for three classes):\n",
    "\n",
    "**RockPaperScissorsCNN Model:**\n",
    "\n",
    "- Test Accuracy: 52.5%\n",
    "\n",
    "- Average Test Loss: 1.040739\n",
    "\n",
    "- This model achieved a moderate accuracy, indicating its ability to classify gestures, but with clear room for improvement.\n",
    "\n",
    "**RockPaperScissorsResNetwork Model:**\n",
    "\n",
    "- Test Accuracy: 73.5%\n",
    "\n",
    "- Average Test Loss: 1.006295\n",
    "\n",
    "- The Residual Network significantly outperformed the simpler CNN, demonstrating a much higher accuracy. This highlights the effectiveness of residual connections in learning more complex features from the image data, even with small image sizes.\n",
    "\n",
    "These results underscore the importance of architectural choices in deep learning, with the ResNet-inspired design proving more effective for this image classification task.\n",
    "\n",
    "**Next Steps & Future Work**\n",
    "Building upon the insights gained from training these custom architectures, the logical next step to further enhance model performance and generalization is to implement transfer learning. This will involve:\n",
    "\n",
    "- Utilizing a pre-trained ResNet model: Leveraging a state-of-the-art ResNet architecture (e.g., ResNet18, ResNet50) pre-trained on a large-scale dataset like ImageNet.\n",
    "\n",
    "- Fine-tuning the model: Adapting the pre-trained model to the specific Rock Paper Scissors classification task by replacing the final classification layer and retraining it on the dataset, potentially with a lower learning rate for earlier layers. This approach is expected to significantly boost accuracy by leveraging features learned from a vast array of images.\n",
    "\n",
    "**Reproducibility**\n",
    "- Random seeds are set at the beginning of the script to ensure the reproducibility of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4802e26a-c6a8-453f-a972-6a284ad1bdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a9e1a454-4991-44e9-b134-6a40a3691465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to 42 for all relevant libraries.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import os # To set environment variables, useful for some libraries\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"\n",
    "    Sets the random seed for reproducibility across different libraries.\n",
    "    \"\"\"\n",
    "    # 1. Set seed for Python's built-in random module\n",
    "    random.seed(seed)\n",
    "\n",
    "    # 2. Set seed for NumPy\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # 3. Set seed for PyTorch (CPU and GPU)\n",
    "    torch.manual_seed(seed) # For CPU operations\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed) # For current GPU\n",
    "        torch.cuda.manual_seed_all(seed) # For all GPUs (if you have multiple)\n",
    "\n",
    "    # 4. Ensure deterministic behavior for CuDNN (GPU operations)\n",
    "    #    This can sometimes slightly slow down training, but ensures exact reproducibility.\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False # Disable CuDNN auto-tuner for deterministic ops\n",
    "\n",
    "    # 5. Set environment variable for Python hashing (affects dicts, sets, etc.)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "    print(f\"Random seed set to {seed} for all relevant libraries.\")\n",
    "\n",
    "MY_RANDOM_SEED = 42\n",
    "set_seed(MY_RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0449044-053f-43eb-b028-95a33c430d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            filename  width  height  class  \\\n",
      "0  egohands-public-1620914960773_png_jpg.rf.aa184...    640     640   Rock   \n",
      "1  egohands-public-1624053434391_png_jpg.rf.aaef5...    640     640  Paper   \n",
      "2  egohands-public-1624465902684_png_jpg.rf.aaa09...    640     640   Rock   \n",
      "3  Screen-Shot-2022-02-08-at-12-59-24-PM_png.rf.a...    640     640   Rock   \n",
      "4  egohands-public-1622127402076_png_jpg.rf.aa897...    640     640   Rock   \n",
      "\n",
      "   xmin  ymin  xmax  ymax  \n",
      "0   429   185   562   319  \n",
      "1   269   354   544   443  \n",
      "2   427   332   551   509  \n",
      "3    80   268   145   395  \n",
      "4    83   128   296   381  \n",
      "egohands-public-1620914960773_png_jpg.rf.aa184eeebad98b2fb04354d01a90b9d0.jpg\n",
      "0\n",
      "class\n",
      "Paper       1349\n",
      "Rock        1924\n",
      "Scissors    1337\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_csv_file_path = 'rock-paper-scissors/train/train/_annotations.csv'\n",
    "train_raw_df = pd.read_csv(train_csv_file_path)\n",
    "\n",
    "print(train_raw_df.head())\n",
    "print(train_raw_df.filename[0])\n",
    "print(train_raw_df.loc[:,'class'].isnull().sum())#So all the images are labelled\n",
    "\n",
    "print(train_raw_df.groupby('class').size()) #So all images correctly belong to either Papper, Rock, Scissors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a99b7bb5-19ea-4bd2-8bc4-7226b10e6777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4610 entries, 0 to 4609\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   filename  4610 non-null   object\n",
      " 1   class     4610 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 72.2+ KB\n",
      "None\n",
      "filename    egohands-public-1620914960773_png_jpg.rf.aa184...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "train_df = train_raw_df.loc[:, ['filename','class']]\n",
    "print(train_df.info())\n",
    "print(train_df.loc[0,['filename']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b5cdff5-444c-48b8-9bf4-38db2f074f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 204 entries, 0 to 203\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   filename  204 non-null    object\n",
      " 1   width     204 non-null    int64 \n",
      " 2   height    204 non-null    int64 \n",
      " 3   class     204 non-null    object\n",
      " 4   xmin      204 non-null    int64 \n",
      " 5   ymin      204 non-null    int64 \n",
      " 6   xmax      204 non-null    int64 \n",
      " 7   ymax      204 non-null    int64 \n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 12.9+ KB\n",
      "None\n",
      "0\n",
      "class\n",
      "Paper       72\n",
      "Rock        65\n",
      "Scissors    67\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "evaluate_csv_file_path ='rock-paper-scissors/test/test/_annotations.csv'\n",
    "\n",
    "evaluate_raw_df = pd.read_csv(evaluate_csv_file_path)\n",
    "\n",
    "print(evaluate_raw_df.info())\n",
    "print(evaluate_raw_df.loc[:,'class'].isnull().sum())#So all the images are labelled\n",
    "\n",
    "print(evaluate_raw_df.groupby('class').size()) #So all images correctly belong to either Papper, Rock, Scissors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb4d8643-890b-489e-9560-0151a724db58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 204 entries, 0 to 203\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   filename  204 non-null    object\n",
      " 1   class     204 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 3.3+ KB\n",
      "None\n",
      "filename    IMG_7079_MOV-23_jpg.rf.123a8de8c8da646e4a25f1c...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "evaluate_df = evaluate_raw_df.loc[:, ['filename','class']]\n",
    "print(evaluate_df.info())\n",
    "print(evaluate_df.loc[0,['filename']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00800216-164a-470d-bf95-423169c4cabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01adaa4b-2224-4a40-a5f7-067f7a457bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "# --- Image dimensions for thr model ---\n",
    "IMAGE_SIZE = 16\n",
    "\n",
    "\n",
    "# --- 1. Define Transformations (same as before, but applied within custom dataset) ---\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)), #for our model to work, it's mandatory to have same size images\n",
    "    transforms.RandomHorizontalFlip(),#a way to artificially increase the dataset, and improve generaliztion\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06764348-4213-4850-91a8-00df9b0e7d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "#Datasets\n",
    "\n",
    "class RockPaperScissorsDataset(Dataset):\n",
    "\n",
    "    def __init__(self,df, img_file_path, transform):\n",
    "        self.df = df\n",
    "        self.img_file_path = img_file_path\n",
    "        self.transform = transform\n",
    "        self.class_to_value = {'Rock': 0, 'Paper': 1, 'Scissors': 2}\n",
    "        self.list_images_tensors =[]\n",
    "        for idx in range(len(df)):\n",
    "            # Open the image\n",
    "            image = Image.open(self.img_file_path + self.df.loc[idx,'filename'])\n",
    "            # Ensure it's RGB (important for consistency)\n",
    "            image = image.convert('RGB')\n",
    "            image_tensor = self.transform(image)\n",
    "            image.close()\n",
    "            self.list_images_tensors.append(image_tensor)\n",
    "            \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        image_tensor = self.list_images_tensors[idx]\n",
    "        ground_truth= self.class_to_value[self.df.loc[idx,'class']]\n",
    "\n",
    "        return image_tensor,ground_truth\n",
    "train_dataset= RockPaperScissorsDataset(train_df,'rock-paper-scissors/train/train/',train_transforms)\n",
    "\n",
    "evaluate_dataset = RockPaperScissorsDataset(evaluate_df, 'rock-paper-scissors/test/test/', test_transforms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c6662b-25b8-4fe6-9319-ac09a59f649e",
   "metadata": {},
   "source": [
    "Printing the result to make sure: that the images are correctly transformed into tensors, and 'class' into a integer from 0 to 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4841e6a-3ec4-4730-8289-a7bf8f73410e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.8706, 0.8824, 0.8902, 0.8627, 0.8627, 0.9059, 0.6549, 0.4510,\n",
      "          0.4863, 0.4471, 0.6980, 0.7098, 0.6706, 0.6471, 0.6275, 0.6275],\n",
      "         [0.8980, 0.9294, 0.9412, 0.9059, 0.8784, 0.8510, 0.5686, 0.5843,\n",
      "          0.5765, 0.4863, 0.5529, 0.6549, 0.6784, 0.7059, 0.6980, 0.7137],\n",
      "         [0.8667, 0.8824, 0.9529, 0.9569, 0.8745, 0.6824, 0.5490, 0.5529,\n",
      "          0.5333, 0.5176, 0.5608, 0.7608, 0.7765, 0.7882, 0.7843, 0.7725],\n",
      "         [0.8353, 0.7451, 0.8471, 0.9098, 0.8627, 0.6824, 0.5961, 0.5804,\n",
      "          0.5647, 0.5804, 0.5686, 0.7490, 0.7373, 0.7725, 0.8078, 0.8314],\n",
      "         [0.8902, 0.8118, 0.8314, 0.8039, 0.6863, 0.6353, 0.6314, 0.6471,\n",
      "          0.6157, 0.6745, 0.6431, 0.9373, 0.9843, 1.0000, 1.0000, 1.0000],\n",
      "         [0.8392, 0.7882, 0.8431, 0.8745, 0.7373, 0.6510, 0.5882, 0.6588,\n",
      "          0.6196, 0.6745, 0.6902, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 0.9333, 1.0000, 1.0000, 0.8706, 0.7490, 0.5137, 0.6784,\n",
      "          0.6549, 0.6314, 0.6941, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 0.9333, 1.0000, 1.0000, 0.8824, 0.7725, 0.4588, 0.6706,\n",
      "          0.6667, 0.5961, 0.6392, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 0.9490, 1.0000, 0.9294, 0.7882, 0.6824, 0.5255, 0.6745,\n",
      "          0.6627, 0.6510, 0.6314, 0.9804, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 0.9412, 0.8824, 0.7020, 0.6510, 0.5451, 0.5255, 0.6471,\n",
      "          0.6745, 0.6627, 0.6431, 0.8078, 0.9961, 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 0.9569, 0.8392, 0.6275, 0.6078, 0.5216, 0.5137, 0.6471,\n",
      "          0.6471, 0.6039, 0.6275, 0.6902, 0.8588, 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 0.9490, 0.8000, 0.6510, 0.6039, 0.4980, 0.5333, 0.6353,\n",
      "          0.5882, 0.5294, 0.5961, 0.6510, 0.7804, 0.9961, 1.0000, 1.0000],\n",
      "         [1.0000, 0.9255, 0.7765, 0.6275, 0.5216, 0.4588, 0.4588, 0.5373,\n",
      "          0.4941, 0.5255, 0.5765, 0.6275, 0.7216, 0.9373, 1.0000, 1.0000],\n",
      "         [0.8039, 0.7647, 0.6863, 0.5529, 0.4627, 0.4549, 0.4392, 0.4392,\n",
      "          0.4471, 0.4941, 0.5412, 0.5961, 0.6824, 0.8196, 0.9647, 0.9765],\n",
      "         [0.7451, 0.7137, 0.6275, 0.5098, 0.4588, 0.4588, 0.4549, 0.4431,\n",
      "          0.4549, 0.4980, 0.5294, 0.5647, 0.6471, 0.6980, 0.7216, 0.6863],\n",
      "         [0.6824, 0.6588, 0.5765, 0.4392, 0.4353, 0.4353, 0.4392, 0.4431,\n",
      "          0.4627, 0.4784, 0.5020, 0.5294, 0.6078, 0.6471, 0.6275, 0.6157]],\n",
      "\n",
      "        [[0.9137, 0.9216, 0.9137, 0.8784, 0.8784, 0.9216, 0.6510, 0.3725,\n",
      "          0.3804, 0.4157, 0.7216, 0.7529, 0.7176, 0.6784, 0.6471, 0.6471],\n",
      "         [0.9569, 0.9765, 0.9686, 0.9137, 0.8824, 0.8549, 0.5373, 0.4588,\n",
      "          0.4314, 0.3961, 0.5412, 0.6588, 0.7020, 0.7333, 0.7333, 0.7373],\n",
      "         [0.9373, 0.9451, 0.9961, 0.9686, 0.8784, 0.6824, 0.4980, 0.4431,\n",
      "          0.4118, 0.4196, 0.5373, 0.7804, 0.8000, 0.8118, 0.8196, 0.8039],\n",
      "         [0.8902, 0.7922, 0.8863, 0.9373, 0.8745, 0.6745, 0.5176, 0.4588,\n",
      "          0.4275, 0.4627, 0.5216, 0.7529, 0.7608, 0.7922, 0.8275, 0.8471],\n",
      "         [0.9451, 0.8549, 0.8824, 0.8471, 0.7137, 0.6196, 0.5216, 0.4824,\n",
      "          0.4510, 0.5176, 0.5882, 0.9333, 0.9922, 1.0000, 1.0000, 1.0000],\n",
      "         [0.8863, 0.8157, 0.8824, 0.8902, 0.7451, 0.6431, 0.5059, 0.5020,\n",
      "          0.4549, 0.5451, 0.6549, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 0.9569, 1.0000, 1.0000, 0.8745, 0.7373, 0.4549, 0.5333,\n",
      "          0.4902, 0.5294, 0.6745, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 0.9686, 1.0000, 1.0000, 0.8824, 0.7451, 0.4078, 0.5412,\n",
      "          0.5176, 0.5176, 0.6275, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 0.9765, 1.0000, 0.9255, 0.7373, 0.5765, 0.4000, 0.5412,\n",
      "          0.5216, 0.5451, 0.5765, 0.9647, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 0.9725, 0.8784, 0.6118, 0.5137, 0.3647, 0.3529, 0.4902,\n",
      "          0.5255, 0.5294, 0.5176, 0.7412, 0.9961, 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 0.9882, 0.7882, 0.4980, 0.4627, 0.3294, 0.3255, 0.4588,\n",
      "          0.4784, 0.4392, 0.4588, 0.5882, 0.8196, 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 0.9765, 0.7451, 0.5216, 0.4431, 0.2863, 0.3412, 0.4588,\n",
      "          0.3961, 0.3529, 0.4196, 0.5373, 0.7137, 0.9922, 1.0000, 1.0000],\n",
      "         [1.0000, 0.9529, 0.7137, 0.4863, 0.3294, 0.2510, 0.2863, 0.3569,\n",
      "          0.3176, 0.3333, 0.3843, 0.4941, 0.6431, 0.9059, 1.0000, 1.0000],\n",
      "         [0.9216, 0.8196, 0.5961, 0.4078, 0.2588, 0.2431, 0.2431, 0.2627,\n",
      "          0.2784, 0.3098, 0.3333, 0.4510, 0.5922, 0.7843, 0.9686, 0.9804],\n",
      "         [0.8549, 0.7176, 0.5216, 0.3529, 0.2471, 0.2392, 0.2471, 0.2588,\n",
      "          0.2667, 0.2902, 0.3137, 0.4118, 0.5451, 0.6314, 0.6941, 0.6863],\n",
      "         [0.7686, 0.6235, 0.4549, 0.3098, 0.2314, 0.2392, 0.2431, 0.2510,\n",
      "          0.2627, 0.2863, 0.2902, 0.3725, 0.5059, 0.5765, 0.6039, 0.6157]],\n",
      "\n",
      "        [[0.8824, 0.8784, 0.8627, 0.8314, 0.8314, 0.8784, 0.6157, 0.3725,\n",
      "          0.3765, 0.3922, 0.6824, 0.7176, 0.6824, 0.6549, 0.6275, 0.6235],\n",
      "         [0.9294, 0.9412, 0.9294, 0.8706, 0.8314, 0.8118, 0.5098, 0.4471,\n",
      "          0.4196, 0.3843, 0.5098, 0.6392, 0.6784, 0.7098, 0.7098, 0.7098],\n",
      "         [0.9098, 0.9059, 0.9608, 0.9294, 0.8314, 0.6431, 0.4863, 0.4392,\n",
      "          0.4078, 0.4118, 0.5059, 0.7569, 0.7843, 0.8039, 0.8118, 0.8000],\n",
      "         [0.8706, 0.7765, 0.8706, 0.9098, 0.8392, 0.6392, 0.5020, 0.4549,\n",
      "          0.4275, 0.4510, 0.5059, 0.7451, 0.7608, 0.8039, 0.8275, 0.8510],\n",
      "         [0.9255, 0.8431, 0.8706, 0.8275, 0.7059, 0.5922, 0.5020, 0.4824,\n",
      "          0.4510, 0.4980, 0.5804, 0.9333, 0.9922, 1.0000, 1.0000, 1.0000],\n",
      "         [0.8902, 0.8275, 0.8902, 0.8941, 0.7451, 0.6157, 0.4902, 0.5020,\n",
      "          0.4588, 0.5294, 0.6510, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 0.9686, 1.0000, 1.0000, 0.8745, 0.7137, 0.4471, 0.5294,\n",
      "          0.4902, 0.5216, 0.6706, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 0.9804, 1.0000, 1.0000, 0.8784, 0.7216, 0.3961, 0.5333,\n",
      "          0.5020, 0.5020, 0.6314, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 0.9922, 1.0000, 0.9255, 0.7255, 0.5843, 0.4078, 0.5216,\n",
      "          0.4980, 0.5294, 0.5922, 0.9647, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 0.9882, 0.8824, 0.6039, 0.5098, 0.4039, 0.3647, 0.4549,\n",
      "          0.4941, 0.5137, 0.5569, 0.7569, 0.9961, 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 0.9961, 0.7843, 0.4980, 0.4588, 0.3686, 0.3490, 0.4314,\n",
      "          0.4549, 0.4510, 0.5137, 0.6039, 0.8039, 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 0.9922, 0.7412, 0.5137, 0.4431, 0.3373, 0.3569, 0.4314,\n",
      "          0.4000, 0.4039, 0.4824, 0.5529, 0.6941, 0.9882, 1.0000, 1.0000],\n",
      "         [1.0000, 0.9686, 0.6980, 0.4745, 0.3569, 0.3059, 0.3176, 0.3569,\n",
      "          0.3490, 0.3843, 0.4471, 0.5137, 0.6196, 0.8902, 1.0000, 1.0000],\n",
      "         [0.9725, 0.8431, 0.5843, 0.4118, 0.3137, 0.2902, 0.3020, 0.3059,\n",
      "          0.3137, 0.3608, 0.4039, 0.4706, 0.5686, 0.7569, 0.9686, 0.9804],\n",
      "         [0.9098, 0.7216, 0.4980, 0.3608, 0.3059, 0.2941, 0.3020, 0.3020,\n",
      "          0.3176, 0.3490, 0.3765, 0.4431, 0.5255, 0.6118, 0.6902, 0.6902],\n",
      "         [0.8275, 0.6157, 0.4471, 0.3255, 0.2863, 0.2824, 0.2902, 0.3020,\n",
      "          0.3137, 0.3255, 0.3529, 0.4078, 0.4863, 0.5490, 0.5843, 0.6078]]]) 0\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[2][0], train_dataset[2][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4471df22-68dc-494d-8b1b-85f78a88b618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 16, 16])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "#let's make the dataloaders \n",
    "training_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "evaluate_dataloader = DataLoader(evaluate_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for X,y in training_dataloader:\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d51cf45e-3e23-4215-8d84-7deb6a188422",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RockPaperScissorsCNN(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels, output_size, images_size, dropout_prob):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(input_channels,hidden_channels, kernel_size=(3,3), stride=(1,1), padding=(1,1) ),\n",
    "            nn.BatchNorm2d(hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(dropout_prob),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(hidden_channels * images_size[0]//2 * images_size[1]//2, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.cnn(x)\n",
    "        return logits \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b9f4af8-c710-4c59-bf06-5ec85cbb14f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels):\n",
    "        super().__init__(),\n",
    "        self.convs = nn.Sequential(\n",
    "            nn.Conv2d(input_channels,hidden_channels, kernel_size=(3,3), stride=(1,1), padding=(1,1)),\n",
    "            nn.BatchNorm2d(hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_channels,2*hidden_channels, kernel_size=(3,3), stride=(1,1), padding=(1,1)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(2*hidden_channels,hidden_channels, kernel_size=(3,3), stride=(1,1), padding=(1,1)),\n",
    "            nn.BatchNorm2d(hidden_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.downsample = None\n",
    "        if input_channels != hidden_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(input_channels, hidden_channels, kernel_size=1, stride=1, bias=False),\n",
    "                nn.BatchNorm2d(hidden_channels)\n",
    "            )\n",
    "            #this way we make sure that F(x) + x is doable as x and F(x)are the same size\n",
    "\n",
    "    def forward(self,x):\n",
    "        output = self.convs(x)\n",
    "        if self.downsample is not None:\n",
    "            x = self.downsample(x)\n",
    "        return output + x # residual connection\n",
    "\n",
    "class RockPaperScissorsResNetwork(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels, output_size, images_size, dropout_prob):\n",
    "        super().__init__()     \n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            ResBlock(input_channels, hidden_channels),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            ResBlock(hidden_channels, hidden_channels),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "            nn.ReLU(),\n",
    "            ResBlock(hidden_channels, hidden_channels),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(hidden_channels * images_size[0]//8 * images_size[1]//8, output_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        logits = self.net(X)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7abe982d-da0d-4d4a-9cae-96fbd9c6739a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channels = 3\n",
    "hidden_channels = 128\n",
    "output_size = 3\n",
    "images_size = (16,16)\n",
    "dropout_prob = 0.3\n",
    "\n",
    "model_CNN = RockPaperScissorsCNN(input_channels, hidden_channels, output_size, images_size, dropout_prob).to(device)\n",
    "model_CNN.load_state_dict(torch.load(\"model_CNN.pth\", weights_only=True))\n",
    "criterion_CNN = nn.CrossEntropyLoss() # We use CrossEntropyLoss as we are solving a classification problem\n",
    "optimizer_CNN = torch.optim.AdamW(model_CNN.parameters(), lr=0.0001, weight_decay=0.0001) \n",
    "\n",
    "model_NET = RockPaperScissorsResNetwork(input_channels, hidden_channels, output_size, images_size, dropout_prob).to(device)\n",
    "model_NET.load_state_dict(torch.load(\"model_NET.pth\", weights_only=True))\n",
    "\n",
    "criterion_NET = nn.CrossEntropyLoss() # We use CrossEntropyLoss as we are solving a classification problem\n",
    "optimizer_NET = torch.optim.AdamW(model_NET.parameters(), lr=0.001, weight_decay=0.0001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e1e0408-158f-4ab1-89e8-1213b332e1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(dataloader,model,criterion, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    total_samples_processed_in_epoch = 0 #Initialize a variable to track the total samples processed in this epoch\n",
    "    model.train()\n",
    "    for batch,(X,y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        pred=model(X)\n",
    "        loss = criterion(pred, y)\n",
    "\n",
    "        loss.backward() # Backpropagation\n",
    "        optimizer.step() #update of weights and biases  \n",
    "        optimizer.zero_grad() #gradient reset \n",
    "\n",
    "        #Accumulate the number of samples processed in the current batch\n",
    "        total_samples_processed_in_epoch += len(X) \n",
    "\n",
    "\n",
    "        if batch%10==0:\n",
    "            loss_val = loss.item()\n",
    "            print(f\"loss: {loss_val:>7f}  [{total_samples_processed_in_epoch:>5d}/{size:>5d}]\")\n",
    "\n",
    "def evaluate_loop(dataloader, model, criterion):\n",
    "    size = len(dataloader.dataset)\n",
    "    elements_per_batch = len(dataloader)\n",
    "    model.eval()\n",
    "    sum_loss_per_batch, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X,y in dataloader:\n",
    "            X,y = X.to(device), y.to(device)\n",
    "\n",
    "            pred = model(X)\n",
    "            sum_loss_per_batch+=criterion(pred,y).item()\n",
    "            correct += (pred.argmax(1)==y).type(torch.float).sum().item()\n",
    "    sum_loss_per_batch/=elements_per_batch\n",
    "    correct/=size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {sum_loss_per_batch:>8f} \\n\")\n",
    "    \n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4fb2ff-090c-4047-9ef0-a4de93f1d4c3",
   "metadata": {},
   "source": [
    "**Let's see the results !**\n",
    "\n",
    "1) CNN model\n",
    "2) ResNet model (Scroll Down to see the results)\n",
    "\n",
    "**CNN model's results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "44baf629-5246-40f1-b03c-64b67d7e60e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.108592  [   64/ 4610]\n",
      "loss: 1.105286  [  704/ 4610]\n",
      "loss: 1.202035  [ 1344/ 4610]\n",
      "loss: 1.003798  [ 1984/ 4610]\n",
      "loss: 1.049031  [ 2624/ 4610]\n",
      "loss: 1.044107  [ 3264/ 4610]\n",
      "loss: 1.043493  [ 3904/ 4610]\n",
      "loss: 1.089199  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 41.7%, Avg loss: 1.095287 \n",
      "\n",
      "Current Learning Rate: 0.000100\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.156426  [   64/ 4610]\n",
      "loss: 1.095022  [  704/ 4610]\n",
      "loss: 1.083768  [ 1344/ 4610]\n",
      "loss: 1.037690  [ 1984/ 4610]\n",
      "loss: 1.004380  [ 2624/ 4610]\n",
      "loss: 1.009202  [ 3264/ 4610]\n",
      "loss: 1.061280  [ 3904/ 4610]\n",
      "loss: 1.047000  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.113992 \n",
      "\n",
      "Current Learning Rate: 0.000100\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.081722  [   64/ 4610]\n",
      "loss: 1.032029  [  704/ 4610]\n",
      "loss: 0.969922  [ 1344/ 4610]\n",
      "loss: 1.033481  [ 1984/ 4610]\n",
      "loss: 1.013139  [ 2624/ 4610]\n",
      "loss: 1.095193  [ 3264/ 4610]\n",
      "loss: 1.054376  [ 3904/ 4610]\n",
      "loss: 0.981264  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 46.6%, Avg loss: 1.063610 \n",
      "\n",
      "Current Learning Rate: 0.000099\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.982526  [   64/ 4610]\n",
      "loss: 0.960459  [  704/ 4610]\n",
      "loss: 1.042549  [ 1344/ 4610]\n",
      "loss: 1.048327  [ 1984/ 4610]\n",
      "loss: 0.974383  [ 2624/ 4610]\n",
      "loss: 1.010435  [ 3264/ 4610]\n",
      "loss: 0.911593  [ 3904/ 4610]\n",
      "loss: 1.035214  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 42.6%, Avg loss: 1.056551 \n",
      "\n",
      "Current Learning Rate: 0.000099\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.121307  [   64/ 4610]\n",
      "loss: 0.975788  [  704/ 4610]\n",
      "loss: 1.128422  [ 1344/ 4610]\n",
      "loss: 0.960618  [ 1984/ 4610]\n",
      "loss: 0.987413  [ 2624/ 4610]\n",
      "loss: 1.001825  [ 3264/ 4610]\n",
      "loss: 0.980239  [ 3904/ 4610]\n",
      "loss: 1.147654  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 45.6%, Avg loss: 1.099834 \n",
      "\n",
      "Current Learning Rate: 0.000098\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.900611  [   64/ 4610]\n",
      "loss: 0.994942  [  704/ 4610]\n",
      "loss: 1.005614  [ 1344/ 4610]\n",
      "loss: 1.027782  [ 1984/ 4610]\n",
      "loss: 0.941725  [ 2624/ 4610]\n",
      "loss: 0.999035  [ 3264/ 4610]\n",
      "loss: 1.052311  [ 3904/ 4610]\n",
      "loss: 0.964828  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 48.0%, Avg loss: 1.090090 \n",
      "\n",
      "Current Learning Rate: 0.000097\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.909880  [   64/ 4610]\n",
      "loss: 1.175644  [  704/ 4610]\n",
      "loss: 1.071448  [ 1344/ 4610]\n",
      "loss: 1.051237  [ 1984/ 4610]\n",
      "loss: 1.041077  [ 2624/ 4610]\n",
      "loss: 0.999123  [ 3264/ 4610]\n",
      "loss: 0.971437  [ 3904/ 4610]\n",
      "loss: 0.999570  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.071941 \n",
      "\n",
      "Current Learning Rate: 0.000096\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.934653  [   64/ 4610]\n",
      "loss: 1.003884  [  704/ 4610]\n",
      "loss: 1.042535  [ 1344/ 4610]\n",
      "loss: 0.971603  [ 1984/ 4610]\n",
      "loss: 0.979208  [ 2624/ 4610]\n",
      "loss: 1.054399  [ 3264/ 4610]\n",
      "loss: 0.988756  [ 3904/ 4610]\n",
      "loss: 1.071850  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 43.1%, Avg loss: 1.038348 \n",
      "\n",
      "Current Learning Rate: 0.000094\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.000014  [   64/ 4610]\n",
      "loss: 1.055611  [  704/ 4610]\n",
      "loss: 1.067465  [ 1344/ 4610]\n",
      "loss: 0.956844  [ 1984/ 4610]\n",
      "loss: 1.016071  [ 2624/ 4610]\n",
      "loss: 0.951468  [ 3264/ 4610]\n",
      "loss: 0.988618  [ 3904/ 4610]\n",
      "loss: 0.905370  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 45.1%, Avg loss: 1.119185 \n",
      "\n",
      "Current Learning Rate: 0.000093\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.027040  [   64/ 4610]\n",
      "loss: 0.989751  [  704/ 4610]\n",
      "loss: 0.951215  [ 1344/ 4610]\n",
      "loss: 0.961727  [ 1984/ 4610]\n",
      "loss: 0.890427  [ 2624/ 4610]\n",
      "loss: 1.063863  [ 3264/ 4610]\n",
      "loss: 1.017630  [ 3904/ 4610]\n",
      "loss: 1.026711  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 48.5%, Avg loss: 1.081616 \n",
      "\n",
      "Current Learning Rate: 0.000091\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.963592  [   64/ 4610]\n",
      "loss: 0.895967  [  704/ 4610]\n",
      "loss: 1.069884  [ 1344/ 4610]\n",
      "loss: 0.901562  [ 1984/ 4610]\n",
      "loss: 1.024852  [ 2624/ 4610]\n",
      "loss: 0.946970  [ 3264/ 4610]\n",
      "loss: 0.946265  [ 3904/ 4610]\n",
      "loss: 0.995659  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 48.5%, Avg loss: 1.037743 \n",
      "\n",
      "Current Learning Rate: 0.000090\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.951869  [   64/ 4610]\n",
      "loss: 0.935706  [  704/ 4610]\n",
      "loss: 0.849319  [ 1344/ 4610]\n",
      "loss: 0.885886  [ 1984/ 4610]\n",
      "loss: 0.892537  [ 2624/ 4610]\n",
      "loss: 0.940916  [ 3264/ 4610]\n",
      "loss: 1.039303  [ 3904/ 4610]\n",
      "loss: 1.052859  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.043711 \n",
      "\n",
      "Current Learning Rate: 0.000088\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.977434  [   64/ 4610]\n",
      "loss: 0.956189  [  704/ 4610]\n",
      "loss: 0.913107  [ 1344/ 4610]\n",
      "loss: 0.882106  [ 1984/ 4610]\n",
      "loss: 1.001553  [ 2624/ 4610]\n",
      "loss: 0.993164  [ 3264/ 4610]\n",
      "loss: 0.804004  [ 3904/ 4610]\n",
      "loss: 0.981822  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 52.0%, Avg loss: 1.051829 \n",
      "\n",
      "Current Learning Rate: 0.000086\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.940886  [   64/ 4610]\n",
      "loss: 0.881387  [  704/ 4610]\n",
      "loss: 0.937114  [ 1344/ 4610]\n",
      "loss: 0.928974  [ 1984/ 4610]\n",
      "loss: 0.927455  [ 2624/ 4610]\n",
      "loss: 0.911050  [ 3264/ 4610]\n",
      "loss: 0.826880  [ 3904/ 4610]\n",
      "loss: 1.011856  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 49.0%, Avg loss: 1.077575 \n",
      "\n",
      "Current Learning Rate: 0.000084\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.940778  [   64/ 4610]\n",
      "loss: 1.032906  [  704/ 4610]\n",
      "loss: 0.946391  [ 1344/ 4610]\n",
      "loss: 0.913435  [ 1984/ 4610]\n",
      "loss: 0.971225  [ 2624/ 4610]\n",
      "loss: 0.916140  [ 3264/ 4610]\n",
      "loss: 1.023799  [ 3904/ 4610]\n",
      "loss: 1.002921  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 47.5%, Avg loss: 1.046440 \n",
      "\n",
      "Current Learning Rate: 0.000081\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.918443  [   64/ 4610]\n",
      "loss: 0.934202  [  704/ 4610]\n",
      "loss: 0.928074  [ 1344/ 4610]\n",
      "loss: 0.891113  [ 1984/ 4610]\n",
      "loss: 0.900510  [ 2624/ 4610]\n",
      "loss: 0.916733  [ 3264/ 4610]\n",
      "loss: 0.937070  [ 3904/ 4610]\n",
      "loss: 0.961777  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 48.0%, Avg loss: 1.022092 \n",
      "\n",
      "Current Learning Rate: 0.000079\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 1.034282  [   64/ 4610]\n",
      "loss: 1.036033  [  704/ 4610]\n",
      "loss: 0.924133  [ 1344/ 4610]\n",
      "loss: 0.930496  [ 1984/ 4610]\n",
      "loss: 0.878269  [ 2624/ 4610]\n",
      "loss: 0.929820  [ 3264/ 4610]\n",
      "loss: 0.969153  [ 3904/ 4610]\n",
      "loss: 0.997903  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 46.6%, Avg loss: 1.043450 \n",
      "\n",
      "Current Learning Rate: 0.000077\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.892326  [   64/ 4610]\n",
      "loss: 1.081307  [  704/ 4610]\n",
      "loss: 0.945398  [ 1344/ 4610]\n",
      "loss: 0.912297  [ 1984/ 4610]\n",
      "loss: 0.996309  [ 2624/ 4610]\n",
      "loss: 0.924607  [ 3264/ 4610]\n",
      "loss: 0.976654  [ 3904/ 4610]\n",
      "loss: 0.896461  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.086317 \n",
      "\n",
      "Current Learning Rate: 0.000074\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.899252  [   64/ 4610]\n",
      "loss: 0.952992  [  704/ 4610]\n",
      "loss: 0.913270  [ 1344/ 4610]\n",
      "loss: 0.898484  [ 1984/ 4610]\n",
      "loss: 0.862066  [ 2624/ 4610]\n",
      "loss: 0.995171  [ 3264/ 4610]\n",
      "loss: 0.815638  [ 3904/ 4610]\n",
      "loss: 0.903889  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 1.079080 \n",
      "\n",
      "Current Learning Rate: 0.000072\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.966096  [   64/ 4610]\n",
      "loss: 0.978151  [  704/ 4610]\n",
      "loss: 0.806569  [ 1344/ 4610]\n",
      "loss: 0.834175  [ 1984/ 4610]\n",
      "loss: 0.990585  [ 2624/ 4610]\n",
      "loss: 0.844730  [ 3264/ 4610]\n",
      "loss: 0.820048  [ 3904/ 4610]\n",
      "loss: 1.029642  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 1.036229 \n",
      "\n",
      "Current Learning Rate: 0.000069\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.901586  [   64/ 4610]\n",
      "loss: 1.003656  [  704/ 4610]\n",
      "loss: 0.870052  [ 1344/ 4610]\n",
      "loss: 0.965262  [ 1984/ 4610]\n",
      "loss: 0.939369  [ 2624/ 4610]\n",
      "loss: 0.890663  [ 3264/ 4610]\n",
      "loss: 0.834335  [ 3904/ 4610]\n",
      "loss: 0.905670  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 51.0%, Avg loss: 1.059702 \n",
      "\n",
      "Current Learning Rate: 0.000066\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.937151  [   64/ 4610]\n",
      "loss: 0.958084  [  704/ 4610]\n",
      "loss: 0.807321  [ 1344/ 4610]\n",
      "loss: 0.838022  [ 1984/ 4610]\n",
      "loss: 0.865327  [ 2624/ 4610]\n",
      "loss: 0.868278  [ 3264/ 4610]\n",
      "loss: 0.870601  [ 3904/ 4610]\n",
      "loss: 0.814734  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 51.5%, Avg loss: 1.043332 \n",
      "\n",
      "Current Learning Rate: 0.000063\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.998847  [   64/ 4610]\n",
      "loss: 0.867288  [  704/ 4610]\n",
      "loss: 1.085725  [ 1344/ 4610]\n",
      "loss: 0.983572  [ 1984/ 4610]\n",
      "loss: 0.952105  [ 2624/ 4610]\n",
      "loss: 0.889460  [ 3264/ 4610]\n",
      "loss: 0.999181  [ 3904/ 4610]\n",
      "loss: 0.991996  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 52.0%, Avg loss: 1.019766 \n",
      "\n",
      "Current Learning Rate: 0.000061\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.865525  [   64/ 4610]\n",
      "loss: 1.006005  [  704/ 4610]\n",
      "loss: 0.997536  [ 1344/ 4610]\n",
      "loss: 0.957440  [ 1984/ 4610]\n",
      "loss: 0.936689  [ 2624/ 4610]\n",
      "loss: 0.876838  [ 3264/ 4610]\n",
      "loss: 0.932716  [ 3904/ 4610]\n",
      "loss: 0.831159  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 50.5%, Avg loss: 1.047370 \n",
      "\n",
      "Current Learning Rate: 0.000058\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.865756  [   64/ 4610]\n",
      "loss: 0.839401  [  704/ 4610]\n",
      "loss: 0.837546  [ 1344/ 4610]\n",
      "loss: 0.868889  [ 1984/ 4610]\n",
      "loss: 0.863139  [ 2624/ 4610]\n",
      "loss: 0.844725  [ 3264/ 4610]\n",
      "loss: 0.987166  [ 3904/ 4610]\n",
      "loss: 0.919195  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 1.031961 \n",
      "\n",
      "Current Learning Rate: 0.000055\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.830524  [   64/ 4610]\n",
      "loss: 0.918623  [  704/ 4610]\n",
      "loss: 0.937287  [ 1344/ 4610]\n",
      "loss: 0.959939  [ 1984/ 4610]\n",
      "loss: 0.937271  [ 2624/ 4610]\n",
      "loss: 0.831146  [ 3264/ 4610]\n",
      "loss: 0.925759  [ 3904/ 4610]\n",
      "loss: 0.908239  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 51.5%, Avg loss: 1.031710 \n",
      "\n",
      "Current Learning Rate: 0.000052\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.982293  [   64/ 4610]\n",
      "loss: 0.948753  [  704/ 4610]\n",
      "loss: 0.917339  [ 1344/ 4610]\n",
      "loss: 0.923953  [ 1984/ 4610]\n",
      "loss: 0.931198  [ 2624/ 4610]\n",
      "loss: 0.899015  [ 3264/ 4610]\n",
      "loss: 0.849911  [ 3904/ 4610]\n",
      "loss: 0.886538  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 53.9%, Avg loss: 1.037945 \n",
      "\n",
      "Current Learning Rate: 0.000049\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.962679  [   64/ 4610]\n",
      "loss: 0.857727  [  704/ 4610]\n",
      "loss: 0.925218  [ 1344/ 4610]\n",
      "loss: 0.893351  [ 1984/ 4610]\n",
      "loss: 0.914415  [ 2624/ 4610]\n",
      "loss: 0.885567  [ 3264/ 4610]\n",
      "loss: 0.841739  [ 3904/ 4610]\n",
      "loss: 0.970038  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 49.0%, Avg loss: 1.058893 \n",
      "\n",
      "Current Learning Rate: 0.000047\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.827511  [   64/ 4610]\n",
      "loss: 0.852641  [  704/ 4610]\n",
      "loss: 0.897797  [ 1344/ 4610]\n",
      "loss: 0.824304  [ 1984/ 4610]\n",
      "loss: 0.867953  [ 2624/ 4610]\n",
      "loss: 0.988823  [ 3264/ 4610]\n",
      "loss: 0.903514  [ 3904/ 4610]\n",
      "loss: 0.869321  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 54.4%, Avg loss: 1.023303 \n",
      "\n",
      "Current Learning Rate: 0.000044\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.826533  [   64/ 4610]\n",
      "loss: 0.917056  [  704/ 4610]\n",
      "loss: 0.913896  [ 1344/ 4610]\n",
      "loss: 0.832038  [ 1984/ 4610]\n",
      "loss: 0.922856  [ 2624/ 4610]\n",
      "loss: 0.832578  [ 3264/ 4610]\n",
      "loss: 0.927869  [ 3904/ 4610]\n",
      "loss: 0.968999  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.040104 \n",
      "\n",
      "Current Learning Rate: 0.000041\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.858862  [   64/ 4610]\n",
      "loss: 0.812328  [  704/ 4610]\n",
      "loss: 0.950335  [ 1344/ 4610]\n",
      "loss: 0.932482  [ 1984/ 4610]\n",
      "loss: 0.895869  [ 2624/ 4610]\n",
      "loss: 0.816780  [ 3264/ 4610]\n",
      "loss: 0.956528  [ 3904/ 4610]\n",
      "loss: 0.879436  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 52.0%, Avg loss: 1.037651 \n",
      "\n",
      "Current Learning Rate: 0.000038\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.833880  [   64/ 4610]\n",
      "loss: 0.829224  [  704/ 4610]\n",
      "loss: 0.841090  [ 1344/ 4610]\n",
      "loss: 0.873584  [ 1984/ 4610]\n",
      "loss: 0.949797  [ 2624/ 4610]\n",
      "loss: 0.974246  [ 3264/ 4610]\n",
      "loss: 0.946719  [ 3904/ 4610]\n",
      "loss: 0.954402  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 51.5%, Avg loss: 1.012114 \n",
      "\n",
      "Current Learning Rate: 0.000036\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.932674  [   64/ 4610]\n",
      "loss: 0.859089  [  704/ 4610]\n",
      "loss: 0.823350  [ 1344/ 4610]\n",
      "loss: 0.890117  [ 1984/ 4610]\n",
      "loss: 0.901842  [ 2624/ 4610]\n",
      "loss: 0.840149  [ 3264/ 4610]\n",
      "loss: 0.882265  [ 3904/ 4610]\n",
      "loss: 0.834460  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.010631 \n",
      "\n",
      "Current Learning Rate: 0.000033\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.868705  [   64/ 4610]\n",
      "loss: 0.887385  [  704/ 4610]\n",
      "loss: 0.846851  [ 1344/ 4610]\n",
      "loss: 0.881786  [ 1984/ 4610]\n",
      "loss: 0.785138  [ 2624/ 4610]\n",
      "loss: 0.863627  [ 3264/ 4610]\n",
      "loss: 0.845794  [ 3904/ 4610]\n",
      "loss: 0.967063  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 1.021696 \n",
      "\n",
      "Current Learning Rate: 0.000031\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.909985  [   64/ 4610]\n",
      "loss: 0.823952  [  704/ 4610]\n",
      "loss: 0.926116  [ 1344/ 4610]\n",
      "loss: 0.775891  [ 1984/ 4610]\n",
      "loss: 0.970143  [ 2624/ 4610]\n",
      "loss: 0.860549  [ 3264/ 4610]\n",
      "loss: 0.938661  [ 3904/ 4610]\n",
      "loss: 0.793890  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 52.0%, Avg loss: 1.035284 \n",
      "\n",
      "Current Learning Rate: 0.000029\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.876792  [   64/ 4610]\n",
      "loss: 0.797891  [  704/ 4610]\n",
      "loss: 0.932105  [ 1344/ 4610]\n",
      "loss: 1.014708  [ 1984/ 4610]\n",
      "loss: 0.843078  [ 2624/ 4610]\n",
      "loss: 0.887831  [ 3264/ 4610]\n",
      "loss: 0.802513  [ 3904/ 4610]\n",
      "loss: 0.905325  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 50.5%, Avg loss: 1.020353 \n",
      "\n",
      "Current Learning Rate: 0.000026\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.800504  [   64/ 4610]\n",
      "loss: 0.793356  [  704/ 4610]\n",
      "loss: 0.875575  [ 1344/ 4610]\n",
      "loss: 0.879666  [ 1984/ 4610]\n",
      "loss: 0.807285  [ 2624/ 4610]\n",
      "loss: 1.010439  [ 3264/ 4610]\n",
      "loss: 0.963489  [ 3904/ 4610]\n",
      "loss: 0.865622  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 51.0%, Avg loss: 1.054436 \n",
      "\n",
      "Current Learning Rate: 0.000024\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.883394  [   64/ 4610]\n",
      "loss: 1.083891  [  704/ 4610]\n",
      "loss: 0.863395  [ 1344/ 4610]\n",
      "loss: 0.821965  [ 1984/ 4610]\n",
      "loss: 0.837213  [ 2624/ 4610]\n",
      "loss: 0.894126  [ 3264/ 4610]\n",
      "loss: 0.980664  [ 3904/ 4610]\n",
      "loss: 0.925645  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 1.025788 \n",
      "\n",
      "Current Learning Rate: 0.000022\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.818331  [   64/ 4610]\n",
      "loss: 0.812119  [  704/ 4610]\n",
      "loss: 0.969893  [ 1344/ 4610]\n",
      "loss: 0.855460  [ 1984/ 4610]\n",
      "loss: 0.964350  [ 2624/ 4610]\n",
      "loss: 0.877375  [ 3264/ 4610]\n",
      "loss: 0.883112  [ 3904/ 4610]\n",
      "loss: 0.910973  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 52.0%, Avg loss: 1.017818 \n",
      "\n",
      "Current Learning Rate: 0.000020\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.903002  [   64/ 4610]\n",
      "loss: 0.860117  [  704/ 4610]\n",
      "loss: 0.979068  [ 1344/ 4610]\n",
      "loss: 0.854507  [ 1984/ 4610]\n",
      "loss: 0.890934  [ 2624/ 4610]\n",
      "loss: 0.795312  [ 3264/ 4610]\n",
      "loss: 0.786746  [ 3904/ 4610]\n",
      "loss: 0.924130  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 51.5%, Avg loss: 1.028159 \n",
      "\n",
      "Current Learning Rate: 0.000019\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.862980  [   64/ 4610]\n",
      "loss: 0.956212  [  704/ 4610]\n",
      "loss: 0.977870  [ 1344/ 4610]\n",
      "loss: 0.876748  [ 1984/ 4610]\n",
      "loss: 0.878880  [ 2624/ 4610]\n",
      "loss: 0.940211  [ 3264/ 4610]\n",
      "loss: 0.938941  [ 3904/ 4610]\n",
      "loss: 0.877227  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 1.017236 \n",
      "\n",
      "Current Learning Rate: 0.000017\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.795406  [   64/ 4610]\n",
      "loss: 0.859379  [  704/ 4610]\n",
      "loss: 0.778524  [ 1344/ 4610]\n",
      "loss: 0.872538  [ 1984/ 4610]\n",
      "loss: 0.815493  [ 2624/ 4610]\n",
      "loss: 0.913948  [ 3264/ 4610]\n",
      "loss: 0.829356  [ 3904/ 4610]\n",
      "loss: 0.863204  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 1.018996 \n",
      "\n",
      "Current Learning Rate: 0.000016\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.928362  [   64/ 4610]\n",
      "loss: 0.899917  [  704/ 4610]\n",
      "loss: 0.835142  [ 1344/ 4610]\n",
      "loss: 0.908129  [ 1984/ 4610]\n",
      "loss: 0.833566  [ 2624/ 4610]\n",
      "loss: 0.893558  [ 3264/ 4610]\n",
      "loss: 0.883115  [ 3904/ 4610]\n",
      "loss: 0.746722  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 52.0%, Avg loss: 1.025741 \n",
      "\n",
      "Current Learning Rate: 0.000014\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.921473  [   64/ 4610]\n",
      "loss: 0.840317  [  704/ 4610]\n",
      "loss: 0.948596  [ 1344/ 4610]\n",
      "loss: 0.848239  [ 1984/ 4610]\n",
      "loss: 0.875607  [ 2624/ 4610]\n",
      "loss: 0.874582  [ 3264/ 4610]\n",
      "loss: 0.925619  [ 3904/ 4610]\n",
      "loss: 0.970716  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 52.0%, Avg loss: 1.029821 \n",
      "\n",
      "Current Learning Rate: 0.000013\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.844550  [   64/ 4610]\n",
      "loss: 0.936046  [  704/ 4610]\n",
      "loss: 0.892190  [ 1344/ 4610]\n",
      "loss: 0.930751  [ 1984/ 4610]\n",
      "loss: 0.766290  [ 2624/ 4610]\n",
      "loss: 0.999307  [ 3264/ 4610]\n",
      "loss: 0.831910  [ 3904/ 4610]\n",
      "loss: 0.827931  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 52.0%, Avg loss: 1.015397 \n",
      "\n",
      "Current Learning Rate: 0.000012\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.786471  [   64/ 4610]\n",
      "loss: 0.918604  [  704/ 4610]\n",
      "loss: 0.937077  [ 1344/ 4610]\n",
      "loss: 0.939546  [ 1984/ 4610]\n",
      "loss: 0.859585  [ 2624/ 4610]\n",
      "loss: 0.851977  [ 3264/ 4610]\n",
      "loss: 0.795115  [ 3904/ 4610]\n",
      "loss: 0.928871  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 1.019341 \n",
      "\n",
      "Current Learning Rate: 0.000011\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.942165  [   64/ 4610]\n",
      "loss: 0.827072  [  704/ 4610]\n",
      "loss: 0.978925  [ 1344/ 4610]\n",
      "loss: 0.806876  [ 1984/ 4610]\n",
      "loss: 0.779835  [ 2624/ 4610]\n",
      "loss: 0.737633  [ 3264/ 4610]\n",
      "loss: 0.976979  [ 3904/ 4610]\n",
      "loss: 0.911360  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.022284 \n",
      "\n",
      "Current Learning Rate: 0.000011\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.819567  [   64/ 4610]\n",
      "loss: 0.828926  [  704/ 4610]\n",
      "loss: 0.912665  [ 1344/ 4610]\n",
      "loss: 0.946163  [ 1984/ 4610]\n",
      "loss: 0.872630  [ 2624/ 4610]\n",
      "loss: 0.773539  [ 3264/ 4610]\n",
      "loss: 0.861857  [ 3904/ 4610]\n",
      "loss: 0.800435  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 1.014898 \n",
      "\n",
      "Current Learning Rate: 0.000010\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.823485  [   64/ 4610]\n",
      "loss: 0.907730  [  704/ 4610]\n",
      "loss: 0.905498  [ 1344/ 4610]\n",
      "loss: 0.943673  [ 1984/ 4610]\n",
      "loss: 0.911832  [ 2624/ 4610]\n",
      "loss: 0.858329  [ 3264/ 4610]\n",
      "loss: 0.945907  [ 3904/ 4610]\n",
      "loss: 0.846830  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.031921 \n",
      "\n",
      "Current Learning Rate: 0.000010\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.773819  [   64/ 4610]\n",
      "loss: 0.837753  [  704/ 4610]\n",
      "loss: 0.802709  [ 1344/ 4610]\n",
      "loss: 0.878968  [ 1984/ 4610]\n",
      "loss: 0.909364  [ 2624/ 4610]\n",
      "loss: 0.853483  [ 3264/ 4610]\n",
      "loss: 0.816224  [ 3904/ 4610]\n",
      "loss: 0.983696  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 52.0%, Avg loss: 1.023463 \n",
      "\n",
      "Current Learning Rate: 0.000010\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "scheduler_CNN = lr_scheduler.CosineAnnealingLR(optimizer_CNN, T_max=epochs, eta_min=1e-5)\n",
    "for iteration in range(epochs):\n",
    "    print(f\"Epoch {iteration+1}\\n-------------------------------\")\n",
    "    training_loop(training_dataloader,model_CNN,criterion_CNN,optimizer_CNN)\n",
    "    evaluate_loop(evaluate_dataloader,model_CNN,criterion_CNN)\n",
    "    scheduler_CNN.step()\n",
    "    #display the current learning rate \n",
    "    current_lr = optimizer_CNN.param_groups[0]['lr']\n",
    "    print(f\"Current Learning Rate: {current_lr:.6f}\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "453ad19f-86ff-43f3-a933-2612ed03d449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model_CNN.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model_CNN.state_dict(), \"model_CNN.pth\") #We save the model\n",
    "print(\"Saved PyTorch Model State to model_CNN.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22190b7-80c7-4e31-8ebf-88677fd581b9",
   "metadata": {},
   "source": [
    "**ResNet model's results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "946ff97f-88b3-4a33-8fe9-11ebacf538be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.006123  [   64/ 4610]\n",
      "loss: 1.291084  [  704/ 4610]\n",
      "loss: 1.333328  [ 1344/ 4610]\n",
      "loss: 1.114921  [ 1984/ 4610]\n",
      "loss: 1.014254  [ 2624/ 4610]\n",
      "loss: 1.178169  [ 3264/ 4610]\n",
      "loss: 1.268657  [ 3904/ 4610]\n",
      "loss: 1.154929  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 35.8%, Avg loss: 1.108067 \n",
      "\n",
      "Current Learning Rate: 0.000999\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.177460  [   64/ 4610]\n",
      "loss: 1.263732  [  704/ 4610]\n",
      "loss: 1.064733  [ 1344/ 4610]\n",
      "loss: 1.135854  [ 1984/ 4610]\n",
      "loss: 1.065321  [ 2624/ 4610]\n",
      "loss: 1.179522  [ 3264/ 4610]\n",
      "loss: 1.073957  [ 3904/ 4610]\n",
      "loss: 1.292013  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 39.7%, Avg loss: 1.168161 \n",
      "\n",
      "Current Learning Rate: 0.000996\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.120754  [   64/ 4610]\n",
      "loss: 1.090776  [  704/ 4610]\n",
      "loss: 1.082383  [ 1344/ 4610]\n",
      "loss: 1.269287  [ 1984/ 4610]\n",
      "loss: 1.079007  [ 2624/ 4610]\n",
      "loss: 1.064023  [ 3264/ 4610]\n",
      "loss: 1.086359  [ 3904/ 4610]\n",
      "loss: 1.158544  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 35.3%, Avg loss: 1.154836 \n",
      "\n",
      "Current Learning Rate: 0.000991\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.051343  [   64/ 4610]\n",
      "loss: 1.242822  [  704/ 4610]\n",
      "loss: 1.089437  [ 1344/ 4610]\n",
      "loss: 0.972368  [ 1984/ 4610]\n",
      "loss: 1.113420  [ 2624/ 4610]\n",
      "loss: 1.040785  [ 3264/ 4610]\n",
      "loss: 1.157891  [ 3904/ 4610]\n",
      "loss: 1.220015  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 44.1%, Avg loss: 1.057275 \n",
      "\n",
      "Current Learning Rate: 0.000984\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.033166  [   64/ 4610]\n",
      "loss: 1.128947  [  704/ 4610]\n",
      "loss: 1.034559  [ 1344/ 4610]\n",
      "loss: 1.006968  [ 1984/ 4610]\n",
      "loss: 1.059097  [ 2624/ 4610]\n",
      "loss: 0.990967  [ 3264/ 4610]\n",
      "loss: 1.150668  [ 3904/ 4610]\n",
      "loss: 0.968114  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 44.6%, Avg loss: 1.095291 \n",
      "\n",
      "Current Learning Rate: 0.000976\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.087406  [   64/ 4610]\n",
      "loss: 1.097080  [  704/ 4610]\n",
      "loss: 1.062071  [ 1344/ 4610]\n",
      "loss: 0.954386  [ 1984/ 4610]\n",
      "loss: 1.099741  [ 2624/ 4610]\n",
      "loss: 0.979646  [ 3264/ 4610]\n",
      "loss: 0.999528  [ 3904/ 4610]\n",
      "loss: 1.200554  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 41.7%, Avg loss: 1.099014 \n",
      "\n",
      "Current Learning Rate: 0.000965\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.822190  [   64/ 4610]\n",
      "loss: 1.051834  [  704/ 4610]\n",
      "loss: 1.012937  [ 1344/ 4610]\n",
      "loss: 0.967307  [ 1984/ 4610]\n",
      "loss: 1.048906  [ 2624/ 4610]\n",
      "loss: 1.163068  [ 3264/ 4610]\n",
      "loss: 0.937846  [ 3904/ 4610]\n",
      "loss: 1.079123  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 37.7%, Avg loss: 1.169282 \n",
      "\n",
      "Current Learning Rate: 0.000953\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.299935  [   64/ 4610]\n",
      "loss: 1.073838  [  704/ 4610]\n",
      "loss: 0.995924  [ 1344/ 4610]\n",
      "loss: 1.114712  [ 1984/ 4610]\n",
      "loss: 1.237706  [ 2624/ 4610]\n",
      "loss: 1.047809  [ 3264/ 4610]\n",
      "loss: 1.089863  [ 3904/ 4610]\n",
      "loss: 1.037722  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 43.1%, Avg loss: 1.082506 \n",
      "\n",
      "Current Learning Rate: 0.000939\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.966276  [   64/ 4610]\n",
      "loss: 1.023529  [  704/ 4610]\n",
      "loss: 1.009794  [ 1344/ 4610]\n",
      "loss: 0.981138  [ 1984/ 4610]\n",
      "loss: 1.016939  [ 2624/ 4610]\n",
      "loss: 1.047819  [ 3264/ 4610]\n",
      "loss: 1.141118  [ 3904/ 4610]\n",
      "loss: 1.089392  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.073285 \n",
      "\n",
      "Current Learning Rate: 0.000923\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.042168  [   64/ 4610]\n",
      "loss: 1.011438  [  704/ 4610]\n",
      "loss: 1.010852  [ 1344/ 4610]\n",
      "loss: 0.986697  [ 1984/ 4610]\n",
      "loss: 1.033974  [ 2624/ 4610]\n",
      "loss: 1.010483  [ 3264/ 4610]\n",
      "loss: 0.957419  [ 3904/ 4610]\n",
      "loss: 1.006880  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 48.5%, Avg loss: 1.046792 \n",
      "\n",
      "Current Learning Rate: 0.000905\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1.095687  [   64/ 4610]\n",
      "loss: 1.124286  [  704/ 4610]\n",
      "loss: 0.937640  [ 1344/ 4610]\n",
      "loss: 0.932802  [ 1984/ 4610]\n",
      "loss: 1.101589  [ 2624/ 4610]\n",
      "loss: 0.941081  [ 3264/ 4610]\n",
      "loss: 1.120319  [ 3904/ 4610]\n",
      "loss: 1.085023  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 48.0%, Avg loss: 1.053598 \n",
      "\n",
      "Current Learning Rate: 0.000886\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.938501  [   64/ 4610]\n",
      "loss: 0.951607  [  704/ 4610]\n",
      "loss: 1.030887  [ 1344/ 4610]\n",
      "loss: 0.930524  [ 1984/ 4610]\n",
      "loss: 0.864807  [ 2624/ 4610]\n",
      "loss: 0.888516  [ 3264/ 4610]\n",
      "loss: 0.930673  [ 3904/ 4610]\n",
      "loss: 0.860409  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 49.5%, Avg loss: 1.037812 \n",
      "\n",
      "Current Learning Rate: 0.000866\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.993500  [   64/ 4610]\n",
      "loss: 0.946156  [  704/ 4610]\n",
      "loss: 0.837066  [ 1344/ 4610]\n",
      "loss: 1.007678  [ 1984/ 4610]\n",
      "loss: 0.897800  [ 2624/ 4610]\n",
      "loss: 0.952664  [ 3264/ 4610]\n",
      "loss: 0.796247  [ 3904/ 4610]\n",
      "loss: 0.846143  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 51.5%, Avg loss: 1.019599 \n",
      "\n",
      "Current Learning Rate: 0.000844\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.960987  [   64/ 4610]\n",
      "loss: 0.855033  [  704/ 4610]\n",
      "loss: 0.818459  [ 1344/ 4610]\n",
      "loss: 0.871118  [ 1984/ 4610]\n",
      "loss: 0.953241  [ 2624/ 4610]\n",
      "loss: 0.921382  [ 3264/ 4610]\n",
      "loss: 0.953039  [ 3904/ 4610]\n",
      "loss: 0.960533  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 1.033617 \n",
      "\n",
      "Current Learning Rate: 0.000821\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.836027  [   64/ 4610]\n",
      "loss: 0.959071  [  704/ 4610]\n",
      "loss: 0.957794  [ 1344/ 4610]\n",
      "loss: 0.913097  [ 1984/ 4610]\n",
      "loss: 0.910672  [ 2624/ 4610]\n",
      "loss: 1.144579  [ 3264/ 4610]\n",
      "loss: 1.016110  [ 3904/ 4610]\n",
      "loss: 0.875113  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 51.5%, Avg loss: 0.968885 \n",
      "\n",
      "Current Learning Rate: 0.000796\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.872141  [   64/ 4610]\n",
      "loss: 0.940656  [  704/ 4610]\n",
      "loss: 0.843428  [ 1344/ 4610]\n",
      "loss: 0.938545  [ 1984/ 4610]\n",
      "loss: 0.694276  [ 2624/ 4610]\n",
      "loss: 0.881895  [ 3264/ 4610]\n",
      "loss: 0.956403  [ 3904/ 4610]\n",
      "loss: 0.809338  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 45.6%, Avg loss: 1.196178 \n",
      "\n",
      "Current Learning Rate: 0.000770\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 1.111108  [   64/ 4610]\n",
      "loss: 0.942084  [  704/ 4610]\n",
      "loss: 0.813575  [ 1344/ 4610]\n",
      "loss: 0.857267  [ 1984/ 4610]\n",
      "loss: 0.832752  [ 2624/ 4610]\n",
      "loss: 0.662121  [ 3264/ 4610]\n",
      "loss: 0.812193  [ 3904/ 4610]\n",
      "loss: 0.902988  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.964718 \n",
      "\n",
      "Current Learning Rate: 0.000743\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.914924  [   64/ 4610]\n",
      "loss: 1.090275  [  704/ 4610]\n",
      "loss: 0.799152  [ 1344/ 4610]\n",
      "loss: 0.813490  [ 1984/ 4610]\n",
      "loss: 0.750364  [ 2624/ 4610]\n",
      "loss: 0.704647  [ 3264/ 4610]\n",
      "loss: 0.827325  [ 3904/ 4610]\n",
      "loss: 0.787688  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 59.3%, Avg loss: 0.953458 \n",
      "\n",
      "Current Learning Rate: 0.000716\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.636672  [   64/ 4610]\n",
      "loss: 0.787504  [  704/ 4610]\n",
      "loss: 0.775597  [ 1344/ 4610]\n",
      "loss: 0.610584  [ 1984/ 4610]\n",
      "loss: 0.674223  [ 2624/ 4610]\n",
      "loss: 0.585678  [ 3264/ 4610]\n",
      "loss: 0.765438  [ 3904/ 4610]\n",
      "loss: 0.728841  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 0.961076 \n",
      "\n",
      "Current Learning Rate: 0.000687\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.951755  [   64/ 4610]\n",
      "loss: 0.794988  [  704/ 4610]\n",
      "loss: 0.714175  [ 1344/ 4610]\n",
      "loss: 0.814290  [ 1984/ 4610]\n",
      "loss: 0.610441  [ 2624/ 4610]\n",
      "loss: 0.632675  [ 3264/ 4610]\n",
      "loss: 0.739436  [ 3904/ 4610]\n",
      "loss: 0.664830  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 62.3%, Avg loss: 0.855226 \n",
      "\n",
      "Current Learning Rate: 0.000658\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.825884  [   64/ 4610]\n",
      "loss: 0.663696  [  704/ 4610]\n",
      "loss: 0.789793  [ 1344/ 4610]\n",
      "loss: 0.564842  [ 1984/ 4610]\n",
      "loss: 0.650720  [ 2624/ 4610]\n",
      "loss: 0.607251  [ 3264/ 4610]\n",
      "loss: 0.770220  [ 3904/ 4610]\n",
      "loss: 0.678849  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 59.8%, Avg loss: 0.946663 \n",
      "\n",
      "Current Learning Rate: 0.000628\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.734861  [   64/ 4610]\n",
      "loss: 0.574198  [  704/ 4610]\n",
      "loss: 0.503204  [ 1344/ 4610]\n",
      "loss: 0.551187  [ 1984/ 4610]\n",
      "loss: 0.505331  [ 2624/ 4610]\n",
      "loss: 0.513983  [ 3264/ 4610]\n",
      "loss: 0.713539  [ 3904/ 4610]\n",
      "loss: 0.621237  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 61.3%, Avg loss: 0.874758 \n",
      "\n",
      "Current Learning Rate: 0.000598\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.463885  [   64/ 4610]\n",
      "loss: 0.642216  [  704/ 4610]\n",
      "loss: 0.668508  [ 1344/ 4610]\n",
      "loss: 0.604987  [ 1984/ 4610]\n",
      "loss: 0.626485  [ 2624/ 4610]\n",
      "loss: 0.618929  [ 3264/ 4610]\n",
      "loss: 0.556617  [ 3904/ 4610]\n",
      "loss: 0.593521  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 59.8%, Avg loss: 0.916582 \n",
      "\n",
      "Current Learning Rate: 0.000567\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.560800  [   64/ 4610]\n",
      "loss: 0.510189  [  704/ 4610]\n",
      "loss: 0.583164  [ 1344/ 4610]\n",
      "loss: 0.474882  [ 1984/ 4610]\n",
      "loss: 0.675332  [ 2624/ 4610]\n",
      "loss: 0.764377  [ 3264/ 4610]\n",
      "loss: 0.698536  [ 3904/ 4610]\n",
      "loss: 0.527761  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 57.4%, Avg loss: 1.068572 \n",
      "\n",
      "Current Learning Rate: 0.000536\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.447259  [   64/ 4610]\n",
      "loss: 0.542817  [  704/ 4610]\n",
      "loss: 0.440757  [ 1344/ 4610]\n",
      "loss: 0.409456  [ 1984/ 4610]\n",
      "loss: 0.483935  [ 2624/ 4610]\n",
      "loss: 0.548714  [ 3264/ 4610]\n",
      "loss: 0.401313  [ 3904/ 4610]\n",
      "loss: 0.421304  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 59.8%, Avg loss: 0.910093 \n",
      "\n",
      "Current Learning Rate: 0.000505\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.691849  [   64/ 4610]\n",
      "loss: 0.436182  [  704/ 4610]\n",
      "loss: 0.470960  [ 1344/ 4610]\n",
      "loss: 0.437781  [ 1984/ 4610]\n",
      "loss: 0.427619  [ 2624/ 4610]\n",
      "loss: 0.405327  [ 3264/ 4610]\n",
      "loss: 0.524997  [ 3904/ 4610]\n",
      "loss: 0.361710  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 60.8%, Avg loss: 0.839838 \n",
      "\n",
      "Current Learning Rate: 0.000474\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.437272  [   64/ 4610]\n",
      "loss: 0.723475  [  704/ 4610]\n",
      "loss: 0.445758  [ 1344/ 4610]\n",
      "loss: 0.368252  [ 1984/ 4610]\n",
      "loss: 0.387726  [ 2624/ 4610]\n",
      "loss: 0.301916  [ 3264/ 4610]\n",
      "loss: 0.433816  [ 3904/ 4610]\n",
      "loss: 0.407671  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 69.6%, Avg loss: 0.846865 \n",
      "\n",
      "Current Learning Rate: 0.000443\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.269538  [   64/ 4610]\n",
      "loss: 0.475995  [  704/ 4610]\n",
      "loss: 0.282699  [ 1344/ 4610]\n",
      "loss: 0.322325  [ 1984/ 4610]\n",
      "loss: 0.336802  [ 2624/ 4610]\n",
      "loss: 0.259649  [ 3264/ 4610]\n",
      "loss: 0.335140  [ 3904/ 4610]\n",
      "loss: 0.319403  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 66.2%, Avg loss: 0.925968 \n",
      "\n",
      "Current Learning Rate: 0.000412\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.311041  [   64/ 4610]\n",
      "loss: 0.343428  [  704/ 4610]\n",
      "loss: 0.401164  [ 1344/ 4610]\n",
      "loss: 0.275934  [ 1984/ 4610]\n",
      "loss: 0.365538  [ 2624/ 4610]\n",
      "loss: 0.380507  [ 3264/ 4610]\n",
      "loss: 0.322084  [ 3904/ 4610]\n",
      "loss: 0.322724  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 68.6%, Avg loss: 0.848963 \n",
      "\n",
      "Current Learning Rate: 0.000382\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.200684  [   64/ 4610]\n",
      "loss: 0.310638  [  704/ 4610]\n",
      "loss: 0.511115  [ 1344/ 4610]\n",
      "loss: 0.291338  [ 1984/ 4610]\n",
      "loss: 0.267635  [ 2624/ 4610]\n",
      "loss: 0.384672  [ 3264/ 4610]\n",
      "loss: 0.408179  [ 3904/ 4610]\n",
      "loss: 0.246908  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 65.7%, Avg loss: 0.858602 \n",
      "\n",
      "Current Learning Rate: 0.000352\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.208210  [   64/ 4610]\n",
      "loss: 0.382703  [  704/ 4610]\n",
      "loss: 0.254687  [ 1344/ 4610]\n",
      "loss: 0.236410  [ 1984/ 4610]\n",
      "loss: 0.204300  [ 2624/ 4610]\n",
      "loss: 0.336851  [ 3264/ 4610]\n",
      "loss: 0.288270  [ 3904/ 4610]\n",
      "loss: 0.374834  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 71.1%, Avg loss: 0.811486 \n",
      "\n",
      "Current Learning Rate: 0.000323\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.164904  [   64/ 4610]\n",
      "loss: 0.481496  [  704/ 4610]\n",
      "loss: 0.191364  [ 1344/ 4610]\n",
      "loss: 0.191768  [ 1984/ 4610]\n",
      "loss: 0.175812  [ 2624/ 4610]\n",
      "loss: 0.206574  [ 3264/ 4610]\n",
      "loss: 0.251384  [ 3904/ 4610]\n",
      "loss: 0.213960  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 69.6%, Avg loss: 0.805449 \n",
      "\n",
      "Current Learning Rate: 0.000294\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.173651  [   64/ 4610]\n",
      "loss: 0.221417  [  704/ 4610]\n",
      "loss: 0.159668  [ 1344/ 4610]\n",
      "loss: 0.090663  [ 1984/ 4610]\n",
      "loss: 0.238875  [ 2624/ 4610]\n",
      "loss: 0.218152  [ 3264/ 4610]\n",
      "loss: 0.163207  [ 3904/ 4610]\n",
      "loss: 0.116908  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 66.2%, Avg loss: 0.837295 \n",
      "\n",
      "Current Learning Rate: 0.000267\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.101391  [   64/ 4610]\n",
      "loss: 0.296687  [  704/ 4610]\n",
      "loss: 0.327119  [ 1344/ 4610]\n",
      "loss: 0.311260  [ 1984/ 4610]\n",
      "loss: 0.301516  [ 2624/ 4610]\n",
      "loss: 0.274759  [ 3264/ 4610]\n",
      "loss: 0.270255  [ 3904/ 4610]\n",
      "loss: 0.122562  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 67.2%, Avg loss: 0.858930 \n",
      "\n",
      "Current Learning Rate: 0.000240\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.137082  [   64/ 4610]\n",
      "loss: 0.145065  [  704/ 4610]\n",
      "loss: 0.148558  [ 1344/ 4610]\n",
      "loss: 0.121237  [ 1984/ 4610]\n",
      "loss: 0.164404  [ 2624/ 4610]\n",
      "loss: 0.164281  [ 3264/ 4610]\n",
      "loss: 0.124234  [ 3904/ 4610]\n",
      "loss: 0.206770  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 68.6%, Avg loss: 0.877677 \n",
      "\n",
      "Current Learning Rate: 0.000214\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.151019  [   64/ 4610]\n",
      "loss: 0.168083  [  704/ 4610]\n",
      "loss: 0.106960  [ 1344/ 4610]\n",
      "loss: 0.150228  [ 1984/ 4610]\n",
      "loss: 0.191412  [ 2624/ 4610]\n",
      "loss: 0.111902  [ 3264/ 4610]\n",
      "loss: 0.112575  [ 3904/ 4610]\n",
      "loss: 0.090840  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 71.1%, Avg loss: 0.931248 \n",
      "\n",
      "Current Learning Rate: 0.000189\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.092374  [   64/ 4610]\n",
      "loss: 0.223026  [  704/ 4610]\n",
      "loss: 0.154286  [ 1344/ 4610]\n",
      "loss: 0.162176  [ 1984/ 4610]\n",
      "loss: 0.104416  [ 2624/ 4610]\n",
      "loss: 0.174326  [ 3264/ 4610]\n",
      "loss: 0.162038  [ 3904/ 4610]\n",
      "loss: 0.170593  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 71.6%, Avg loss: 0.900673 \n",
      "\n",
      "Current Learning Rate: 0.000166\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.145007  [   64/ 4610]\n",
      "loss: 0.090470  [  704/ 4610]\n",
      "loss: 0.114554  [ 1344/ 4610]\n",
      "loss: 0.079857  [ 1984/ 4610]\n",
      "loss: 0.153509  [ 2624/ 4610]\n",
      "loss: 0.151488  [ 3264/ 4610]\n",
      "loss: 0.109274  [ 3904/ 4610]\n",
      "loss: 0.060383  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 72.1%, Avg loss: 0.849781 \n",
      "\n",
      "Current Learning Rate: 0.000144\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.079242  [   64/ 4610]\n",
      "loss: 0.139878  [  704/ 4610]\n",
      "loss: 0.121566  [ 1344/ 4610]\n",
      "loss: 0.054303  [ 1984/ 4610]\n",
      "loss: 0.069838  [ 2624/ 4610]\n",
      "loss: 0.059711  [ 3264/ 4610]\n",
      "loss: 0.069117  [ 3904/ 4610]\n",
      "loss: 0.066301  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 72.5%, Avg loss: 0.907723 \n",
      "\n",
      "Current Learning Rate: 0.000124\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.067422  [   64/ 4610]\n",
      "loss: 0.120468  [  704/ 4610]\n",
      "loss: 0.057142  [ 1344/ 4610]\n",
      "loss: 0.064203  [ 1984/ 4610]\n",
      "loss: 0.049219  [ 2624/ 4610]\n",
      "loss: 0.066521  [ 3264/ 4610]\n",
      "loss: 0.066047  [ 3904/ 4610]\n",
      "loss: 0.083105  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 69.6%, Avg loss: 0.902123 \n",
      "\n",
      "Current Learning Rate: 0.000105\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.040402  [   64/ 4610]\n",
      "loss: 0.058174  [  704/ 4610]\n",
      "loss: 0.087868  [ 1344/ 4610]\n",
      "loss: 0.073448  [ 1984/ 4610]\n",
      "loss: 0.052226  [ 2624/ 4610]\n",
      "loss: 0.039502  [ 3264/ 4610]\n",
      "loss: 0.077789  [ 3904/ 4610]\n",
      "loss: 0.091809  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 70.6%, Avg loss: 1.002659 \n",
      "\n",
      "Current Learning Rate: 0.000087\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.060974  [   64/ 4610]\n",
      "loss: 0.071419  [  704/ 4610]\n",
      "loss: 0.098437  [ 1344/ 4610]\n",
      "loss: 0.054785  [ 1984/ 4610]\n",
      "loss: 0.077409  [ 2624/ 4610]\n",
      "loss: 0.085122  [ 3264/ 4610]\n",
      "loss: 0.068262  [ 3904/ 4610]\n",
      "loss: 0.047676  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 72.1%, Avg loss: 0.922801 \n",
      "\n",
      "Current Learning Rate: 0.000071\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.064241  [   64/ 4610]\n",
      "loss: 0.177887  [  704/ 4610]\n",
      "loss: 0.062949  [ 1344/ 4610]\n",
      "loss: 0.060144  [ 1984/ 4610]\n",
      "loss: 0.056726  [ 2624/ 4610]\n",
      "loss: 0.062727  [ 3264/ 4610]\n",
      "loss: 0.067599  [ 3904/ 4610]\n",
      "loss: 0.038821  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 70.6%, Avg loss: 0.936411 \n",
      "\n",
      "Current Learning Rate: 0.000057\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.037605  [   64/ 4610]\n",
      "loss: 0.136235  [  704/ 4610]\n",
      "loss: 0.078842  [ 1344/ 4610]\n",
      "loss: 0.051365  [ 1984/ 4610]\n",
      "loss: 0.043234  [ 2624/ 4610]\n",
      "loss: 0.078399  [ 3264/ 4610]\n",
      "loss: 0.044262  [ 3904/ 4610]\n",
      "loss: 0.074132  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 73.0%, Avg loss: 0.969133 \n",
      "\n",
      "Current Learning Rate: 0.000045\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.040172  [   64/ 4610]\n",
      "loss: 0.065522  [  704/ 4610]\n",
      "loss: 0.041796  [ 1344/ 4610]\n",
      "loss: 0.054779  [ 1984/ 4610]\n",
      "loss: 0.046331  [ 2624/ 4610]\n",
      "loss: 0.032125  [ 3264/ 4610]\n",
      "loss: 0.072443  [ 3904/ 4610]\n",
      "loss: 0.048379  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 71.6%, Avg loss: 0.948731 \n",
      "\n",
      "Current Learning Rate: 0.000034\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.075025  [   64/ 4610]\n",
      "loss: 0.052060  [  704/ 4610]\n",
      "loss: 0.047006  [ 1344/ 4610]\n",
      "loss: 0.023447  [ 1984/ 4610]\n",
      "loss: 0.064750  [ 2624/ 4610]\n",
      "loss: 0.043886  [ 3264/ 4610]\n",
      "loss: 0.029445  [ 3904/ 4610]\n",
      "loss: 0.084984  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 73.5%, Avg loss: 0.954581 \n",
      "\n",
      "Current Learning Rate: 0.000026\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.039483  [   64/ 4610]\n",
      "loss: 0.047407  [  704/ 4610]\n",
      "loss: 0.065458  [ 1344/ 4610]\n",
      "loss: 0.051011  [ 1984/ 4610]\n",
      "loss: 0.038547  [ 2624/ 4610]\n",
      "loss: 0.034273  [ 3264/ 4610]\n",
      "loss: 0.037785  [ 3904/ 4610]\n",
      "loss: 0.027236  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 73.0%, Avg loss: 0.948256 \n",
      "\n",
      "Current Learning Rate: 0.000019\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.035945  [   64/ 4610]\n",
      "loss: 0.031851  [  704/ 4610]\n",
      "loss: 0.062573  [ 1344/ 4610]\n",
      "loss: 0.060359  [ 1984/ 4610]\n",
      "loss: 0.033829  [ 2624/ 4610]\n",
      "loss: 0.060145  [ 3264/ 4610]\n",
      "loss: 0.024346  [ 3904/ 4610]\n",
      "loss: 0.026626  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 73.0%, Avg loss: 0.961466 \n",
      "\n",
      "Current Learning Rate: 0.000014\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.044756  [   64/ 4610]\n",
      "loss: 0.040440  [  704/ 4610]\n",
      "loss: 0.049414  [ 1344/ 4610]\n",
      "loss: 0.064643  [ 1984/ 4610]\n",
      "loss: 0.040216  [ 2624/ 4610]\n",
      "loss: 0.042892  [ 3264/ 4610]\n",
      "loss: 0.048326  [ 3904/ 4610]\n",
      "loss: 0.025749  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 73.0%, Avg loss: 0.969895 \n",
      "\n",
      "Current Learning Rate: 0.000011\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.042320  [   64/ 4610]\n",
      "loss: 0.037679  [  704/ 4610]\n",
      "loss: 0.029983  [ 1344/ 4610]\n",
      "loss: 0.036877  [ 1984/ 4610]\n",
      "loss: 0.056274  [ 2624/ 4610]\n",
      "loss: 0.034662  [ 3264/ 4610]\n",
      "loss: 0.068851  [ 3904/ 4610]\n",
      "loss: 0.051538  [ 4544/ 4610]\n",
      "Test Error: \n",
      " Accuracy: 73.5%, Avg loss: 1.006295 \n",
      "\n",
      "Current Learning Rate: 0.000010\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "scheduler_NET = lr_scheduler.CosineAnnealingLR(optimizer_NET, T_max=epochs, eta_min=1e-5)\n",
    "for iteration in range(epochs):\n",
    "    print(f\"Epoch {iteration+1}\\n-------------------------------\")\n",
    "    training_loop(training_dataloader,model_NET,criterion_NET,optimizer_NET)\n",
    "    evaluate_loop(evaluate_dataloader,model_NET,criterion_NET)\n",
    "    scheduler_NET.step()\n",
    "    #display the current learning rate \n",
    "    current_lr = optimizer_NET.param_groups[0]['lr']\n",
    "    print(f\"Current Learning Rate: {current_lr:.6f}\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "93a55750-bdb5-40b6-8d38-6b86720a42f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163\n",
      "predicted class by ResNet : Paper\n",
      "predicted class by CNN : Paper\n",
      "ground_truth class : Paper\n"
     ]
    }
   ],
   "source": [
    "value_to_class = {0 : 'Rock', 1 :'Paper', 2 : 'Scissors'}\n",
    "n = random.randint(0, 203)\n",
    "\n",
    "print(n)\n",
    "X,y = evaluate_dataset[n]\n",
    "X = X.to(device).unsqueeze(0)\n",
    "model_CNN.to(device)\n",
    "model_CNN.eval()\n",
    "model_NET.to(device)\n",
    "model_NET.eval()\n",
    "with torch.no_grad():\n",
    "    pred_NET = model_NET(X)\n",
    "    pred_CNN = model_CNN(X)\n",
    "    print(f'predicted class by ResNet : {value_to_class[pred_NET.argmax(1)[0].item()]}')\n",
    "    print(f'predicted class by CNN : {value_to_class[pred_CNN.argmax(1)[0].item()]}')\n",
    "    print(f'ground_truth class : {value_to_class[y]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f06268d-535e-4e31-9092-ba3d0c636afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model_NET.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model_NET.state_dict(), \"model_NET.pth\") #We save the model\n",
    "print(\"Saved PyTorch Model State to model_NET.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
